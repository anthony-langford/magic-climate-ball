#!/usr/bin/env python3
"""
Unified Weather Forecasting Pipeline
====================================

A streamlined, all-in-one weather forecasting system that:
1. Downloads historical weather data from Environment Canada
2. Creates clean ML features (avoiding data leakage)
3. Trains the best-performing neural network model
4. Provides easy-to-use forecasting interface

Usage:
    python weather_forecast.py --station-id 47687 --location "Temagami, ON"
    python weather_forecast.py --help

Author: Automated Weather Forecasting System
"""

import argparse
import pandas as pd
import numpy as np
import requests
import io
import time
import pickle
import warnings
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union

from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import TimeSeriesSplit

warnings.filterwarnings("ignore")


class WeatherForecastPipeline:
    """Complete weather forecasting pipeline"""

    def __init__(self, station_id: int, location_name: str = "Unknown"):
        """
        Initialize the weather forecasting pipeline

        Args:
            station_id: Environment Canada station ID
            location_name: Human-readable location name
        """
        self.station_id = station_id
        self.location_name = location_name
        self.raw_data = None
        self.features_data = None
        self.model = None
        self.scaler = None
        self.feature_names = None
        self.model_performance = None

        print(f"ğŸŒ¡ï¸  Weather Forecasting Pipeline")
        print(f"ğŸ“ Location: {location_name}")
        print(f"ğŸ  Station ID: {station_id}")
        print("=" * 60)

    def download_historical_data(
        self, start_year: int = 1990, end_year: int = None, force_download: bool = False
    ) -> pd.DataFrame:
        """
        Download historical weather data from Environment Canada or load from existing file

        Args:
            start_year: Start year for data download
            end_year: End year for data download (default: current year)
            force_download: Force re-download even if cached file exists

        Returns:
            DataFrame with historical weather data
        """

        if end_year is None:
            end_year = datetime.now().year

        # Check for existing data file first
        cache_filename = (
            f"weather_data_station_{self.station_id}_{start_year}_{end_year}.csv"
        )

        # If force_download, clean up old cache files first
        if force_download:
            old_cache_files = list(
                Path(".").glob(f"weather_data_station_{self.station_id}_*.csv")
            )
            if old_cache_files:
                print(f"ğŸ—‘ï¸  Cleaning up {len(old_cache_files)} old cache file(s)...")
                for old_file in old_cache_files:
                    try:
                        old_file.unlink()
                        print(f"   Deleted: {old_file.name}")
                    except Exception as e:
                        print(f"   Could not delete {old_file.name}: {e}")

        if not force_download and Path(cache_filename).exists():
            print(f"ğŸ“‚ Loading existing weather data from {cache_filename}...")
            try:
                cached_data = pd.read_csv(cache_filename, index_col=0, parse_dates=True)

                # Check if cached data has the multi-temperature format we need
                required_temp_cols = ["temp_max", "temp_min", "temp_mean"]
                has_multi_temp = all(
                    col in cached_data.columns for col in required_temp_cols
                )

                if has_multi_temp:
                    # New format - has all temperature types
                    self.raw_data = cached_data
                    print(
                        f"âœ… Loaded {len(self.raw_data)} temperature records from cache (multi-temperature format)"
                    )
                    print(
                        f"ğŸ“… Date range: {self.raw_data.index.min().date()} to {self.raw_data.index.max().date()}"
                    )
                    print(f"ğŸŒ¡ï¸  Temperature ranges:")
                    print(
                        f"   Max: {self.raw_data['temp_max'].min():.1f}Â°C to {self.raw_data['temp_max'].max():.1f}Â°C"
                    )
                    print(
                        f"   Min: {self.raw_data['temp_min'].min():.1f}Â°C to {self.raw_data['temp_min'].max():.1f}Â°C"
                    )
                    print(
                        f"   Mean: {self.raw_data['temp_mean'].min():.1f}Â°C to {self.raw_data['temp_mean'].max():.1f}Â°C"
                    )
                    return self.raw_data
                else:
                    # Old format - need to re-download to get all temperature types
                    print(f"âš ï¸  Cached data is in old format (only mean temperature)")
                    print(
                        f"ğŸ“¥ Re-downloading to get max, min, and mean temperatures..."
                    )
                    # Continue to download fresh data

            except Exception as e:
                print(f"âš ï¸  Error loading cached data: {e}")
                print("ğŸ“¥ Falling back to downloading fresh data...")

        # If no cache or force_download, proceed with download
        print(f"ğŸ“¥ Downloading weather data ({start_year}-{end_year})...")

        frames = []
        years_downloaded = 0

        for year in range(start_year, end_year + 1):
            url = (
                "https://climate.weather.gc.ca/climate_data/bulk_data_e.html"
                f"?format=csv&stationID={self.station_id}&Year={year}&timeframe=2&submit=Download+Data"
            )

            try:
                print(f"  Downloading {year}...", end="", flush=True)

                response = requests.get(url, timeout=30)
                response.raise_for_status()

                # Check if we got CSV data (not HTML error page)
                if (
                    response.text.startswith("<!DOCTYPE")
                    or "<html" in response.text[:100].lower()
                ):
                    print(" âŒ No data")
                    continue

                # Parse CSV
                df = pd.read_csv(io.StringIO(response.text))

                if df.empty or len(df) < 50:  # Minimum threshold for valid data
                    print(" âŒ Empty")
                    continue

                frames.append(df)
                years_downloaded += 1
                print(f" âœ“ {len(df)} records")

            except Exception as e:
                print(f" âŒ Error: {e}")
                continue

            # Be polite to the server
            time.sleep(0.5)

        if not frames:
            # Try to load any existing data as fallback
            fallback_files = list(
                Path(".").glob(f"weather_data_station_{self.station_id}_*.csv")
            )
            if fallback_files:
                print(
                    f"âš ï¸  No new data downloaded, trying existing file: {fallback_files[0]}"
                )
                self.raw_data = pd.read_csv(
                    fallback_files[0], index_col=0, parse_dates=True
                )
                return self.raw_data
            else:
                raise ValueError(
                    f"No weather data could be downloaded for station {self.station_id}"
                )

        # Combine all years
        self.raw_data = pd.concat(frames, ignore_index=True)

        # Clean up the data
        self.raw_data["Date/Time"] = pd.to_datetime(self.raw_data["Date/Time"])
        self.raw_data = self.raw_data.set_index("Date/Time").sort_index()

        # Focus on temperature data - load all three types
        temp_cols = {
            "max": "Max Temp (Â°C)",
            "min": "Min Temp (Â°C)",
            "mean": "Mean Temp (Â°C)",
        }

        for temp_type, col_name in temp_cols.items():
            if col_name not in self.raw_data.columns:
                # Try alternative column names
                alt_cols = [
                    col
                    for col in self.raw_data.columns
                    if "temp" in col.lower() and temp_type in col.lower()
                ]
                if alt_cols:
                    col_name = alt_cols[0]
                else:
                    raise ValueError(
                        f"Could not find {temp_type} temperature column in downloaded data"
                    )

            # Clean temperature data
            self.raw_data[f"temp_{temp_type}"] = pd.to_numeric(
                self.raw_data[col_name], errors="coerce"
            )

        # Remove rows where any temperature is missing
        temp_columns = ["temp_max", "temp_min", "temp_mean"]
        self.raw_data = self.raw_data.dropna(subset=temp_columns)

        # Save to cache for future use (with all temperature types)
        try:
            # Save complete data including all temperature columns
            self.raw_data.to_csv(cache_filename)
            print(f"ğŸ’¾ Multi-temperature data cached to {cache_filename}")
        except Exception as e:
            print(f"âš ï¸  Could not save cache file: {e}")

        print(f"âœ… Downloaded {len(self.raw_data)} temperature records")
        print(
            f"ğŸ“… Date range: {self.raw_data.index.min().date()} to {self.raw_data.index.max().date()}"
        )
        print(f"ğŸŒ¡ï¸  Temperature ranges:")
        print(
            f"   Max: {self.raw_data['temp_max'].min():.1f}Â°C to {self.raw_data['temp_max'].max():.1f}Â°C"
        )
        print(
            f"   Min: {self.raw_data['temp_min'].min():.1f}Â°C to {self.raw_data['temp_min'].max():.1f}Â°C"
        )
        print(
            f"   Mean: {self.raw_data['temp_mean'].min():.1f}Â°C to {self.raw_data['temp_mean'].max():.1f}Â°C"
        )

        return self.raw_data

    def create_ml_features(self) -> pd.DataFrame:
        """
        Create clean ML features from raw weather data for multi-temperature prediction
        Carefully avoids data leakage by using only historical information

        Returns:
            DataFrame with ML-ready features for max, min, and mean temperature prediction
        """

        if self.raw_data is None:
            raise ValueError(
                "No raw data available. Run download_historical_data() first."
            )

        print("ğŸ”§ Creating ML features for multi-temperature prediction...")

        # Temperature data for all three types
        temp_types = ["max", "min", "mean"]
        temp_data = {}
        for temp_type in temp_types:
            temp_data[temp_type] = self.raw_data[f"temp_{temp_type}"].copy()

        # Create feature dataframe
        features_df = pd.DataFrame(index=self.raw_data.index)

        # Add target variables
        for temp_type in temp_types:
            features_df[f"temp_{temp_type}"] = temp_data[temp_type]

        # 1. Temporal features (always safe)
        features_df["day_of_year"] = features_df.index.dayofyear
        features_df["month"] = features_df.index.month
        features_df["sin_doy"] = np.sin(2 * np.pi * features_df["day_of_year"] / 365.25)
        features_df["cos_doy"] = np.cos(2 * np.pi * features_df["day_of_year"] / 365.25)

        # 2. Lag features for all temperature types
        print("  Adding lag features for max, min, and mean temperatures...")
        lag_days = [1, 7, 14, 30]

        for temp_type in temp_types:
            for lag in lag_days:
                features_df[f"{temp_type}_lag_{lag}"] = temp_data[temp_type].shift(lag)

        # 3. Rolling averages (carefully calculated to avoid leakage)
        print("  Adding rolling averages for all temperature types...")

        # 7-day rolling average (excluding current day and yesterday)
        for temp_type in temp_types:
            rolling_7d = []
            temp_series = temp_data[temp_type]

            for i in range(len(temp_series)):
                if i >= 8:  # Need at least 8 previous days
                    historical_temps = temp_series.iloc[i - 8 : i - 1]  # Days 2-8 ago
                    rolling_7d.append(historical_temps.mean())
                else:
                    rolling_7d.append(np.nan)

            features_df[f"{temp_type}_roll_7d"] = rolling_7d

        # 30-day rolling average (excluding current day and last week)
        for temp_type in temp_types:
            rolling_30d = []
            temp_series = temp_data[temp_type]

            for i in range(len(temp_series)):
                if i >= 37:  # Need at least 37 previous days
                    historical_temps = temp_series.iloc[i - 37 : i - 7]  # Days 8-37 ago
                    rolling_30d.append(historical_temps.mean())
                else:
                    rolling_30d.append(np.nan)

            features_df[f"{temp_type}_roll_30d"] = rolling_30d

        # 4. Temperature volatility (standard deviation)
        print("  Adding temperature volatility features...")
        for temp_type in temp_types:
            rolling_std = []
            temp_series = temp_data[temp_type]

            for i in range(len(temp_series)):
                if i >= 15:  # Need at least 15 previous days
                    historical_temps = temp_series.iloc[i - 15 : i - 1]  # Days 2-15 ago
                    rolling_std.append(historical_temps.std())
                else:
                    rolling_std.append(np.nan)

            features_df[f"{temp_type}_std_14d"] = rolling_std

        # 5. Temperature range features (daily max-min difference)
        print("  Adding temperature range features...")
        features_df["temp_range_lag_1"] = (temp_data["max"] - temp_data["min"]).shift(1)
        features_df["temp_range_lag_7"] = (temp_data["max"] - temp_data["min"]).shift(7)

        # 6. Seasonal features
        features_df["is_winter"] = (
            (features_df["month"] == 12)
            | (features_df["month"] == 1)
            | (features_df["month"] == 2)
        ).astype(int)
        features_df["is_summer"] = (
            (features_df["month"] >= 6) & (features_df["month"] <= 8)
        ).astype(int)

        # Remove rows with NaN values
        features_df = features_df.dropna()

        # Store feature names (excluding targets)
        target_columns = [f"temp_{temp_type}" for temp_type in temp_types]
        self.feature_names = [
            col for col in features_df.columns if col not in target_columns
        ]

        print(
            f"âœ… Created {len(self.feature_names)} features for multi-temperature prediction"
        )
        print(f"ğŸ“Š Clean dataset: {len(features_df)} observations")
        print(f"ğŸ¯ Predicting: Max, Min, and Mean daily temperatures")
        print(f"ğŸ” Feature categories:")
        print(f"   â€¢ Temporal: 6 features (day of year, month, seasonal cycles)")
        print(
            f"   â€¢ Lag features: {len([f for f in self.feature_names if 'lag' in f])} features"
        )
        print(
            f"   â€¢ Rolling averages: {len([f for f in self.feature_names if 'roll' in f])} features"
        )
        print(
            f"   â€¢ Volatility: {len([f for f in self.feature_names if 'std' in f])} features"
        )
        print(
            f"   â€¢ Temperature range: {len([f for f in self.feature_names if 'range' in f])} features"
        )

        self.features_data = features_df
        return features_df

    def train_model(self, test_size_years: int = 2) -> Dict:
        """
        Train the multi-output neural network model for max, min, and mean temperature prediction

        Args:
            test_size_years: Number of years to reserve for testing

        Returns:
            Dictionary with training results and performance metrics
        """

        if self.features_data is None:
            raise ValueError("No features available. Run create_ml_features() first.")

        print("ğŸš€ Training multi-output neural network model...")

        # Prepare data for multi-output prediction
        X = self.features_data[self.feature_names].values
        y = self.features_data[
            ["temp_max", "temp_min", "temp_mean"]
        ].values  # Multi-output target
        dates = self.features_data.index

        # Time-based train/test split
        split_date = dates.max() - pd.Timedelta(days=365 * test_size_years)
        train_mask = dates <= split_date

        X_train, X_test = X[train_mask], X[~train_mask]
        y_train, y_test = y[train_mask], y[~train_mask]

        print(f"ğŸ“š Training samples: {len(X_train)} (until {split_date.date()})")
        print(f"ğŸ§ª Testing samples: {len(X_test)}")
        print(f"ğŸ¯ Predicting: Max, Min, and Mean temperatures simultaneously")

        # Scale features
        self.scaler = StandardScaler()
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)

        # Train multi-output neural network
        self.model = MLPRegressor(
            hidden_layer_sizes=(150, 75, 25),  # Slightly larger for multi-output
            activation="relu",
            alpha=0.01,
            learning_rate="adaptive",
            max_iter=500,
            random_state=42,
            early_stopping=True,
            validation_fraction=0.1,
            n_iter_no_change=10,
        )

        print("ğŸ§  Training multi-output neural network...")
        self.model.fit(X_train_scaled, y_train)

        # Evaluate performance for each temperature type
        train_pred = self.model.predict(X_train_scaled)
        test_pred = self.model.predict(X_test_scaled)

        # Calculate MAE for each temperature type
        temp_types = ["max", "min", "mean"]
        train_maes = {}
        test_maes = {}

        for i, temp_type in enumerate(temp_types):
            train_maes[temp_type] = mean_absolute_error(y_train[:, i], train_pred[:, i])
            test_maes[temp_type] = mean_absolute_error(y_test[:, i], test_pred[:, i])

        # Overall performance metrics
        overall_train_mae = np.mean(list(train_maes.values()))
        overall_test_mae = np.mean(list(test_maes.values()))

        # Store performance metrics
        self.model_performance = {
            "train_mae_overall": overall_train_mae,
            "test_mae_overall": overall_test_mae,
            "train_mae_by_type": train_maes,
            "test_mae_by_type": test_maes,
            "train_samples": len(X_train),
            "test_samples": len(X_test),
            "split_date": split_date.strftime("%Y-%m-%d"),
            "features_used": len(self.feature_names),
            "model_type": "Multi-Output Neural Network (MLPRegressor)",
            "architecture": "150-75-25 hidden layers",
            "output_types": temp_types,
        }

        print(f"âœ… Multi-output model training complete!")
        print(f"ğŸ“ˆ Training Performance:")
        for temp_type, mae in train_maes.items():
            print(f"   {temp_type.capitalize():>4} temp: {mae:.3f}Â°C MAE")
        print(f"   Overall: {overall_train_mae:.3f}Â°C MAE")

        print(f"ğŸ“Š Testing Performance:")
        for temp_type, mae in test_maes.items():
            print(f"   {temp_type.capitalize():>4} temp: {mae:.3f}Â°C MAE")
        print(f"   Overall: {overall_test_mae:.3f}Â°C MAE")

        if overall_test_mae < 3.0:
            print("ğŸ‰ Excellent multi-output model performance!")
        elif overall_test_mae < 4.0:
            print("âœ… Good multi-output model performance!")
        else:
            print("ğŸ“Š Acceptable multi-output model performance")

        return self.model_performance

    def _load_full_weather_data(self) -> pd.DataFrame:
        """Load full weather data from cache files for feature generation"""

        # Try to find cached weather data file for this specific station
        cache_files = list(
            Path(".").glob(f"weather_data_station_{self.station_id}_*.csv")
        )

        if cache_files:
            # Sort by modification time, use the most recent
            cache_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            cache_file = cache_files[0]

            print(f"ğŸ“Š Loading full weather data from {cache_file.name}")

            try:
                df = pd.read_csv(cache_file, index_col=0, parse_dates=True)

                # Check if the loaded data has multi-temperature format
                required_temp_cols = ["temp_max", "temp_min", "temp_mean"]
                has_multi_temp = all(col in df.columns for col in required_temp_cols)

                if has_multi_temp:
                    return df
                else:
                    print(
                        f"âŒ Cache file {cache_file.name} is in old single-temperature format"
                    )
                    print(f"ğŸ—‘ï¸  Removing incompatible cache file...")

                    # Remove ALL old cache files for this station
                    for old_cache in cache_files:
                        try:
                            old_cache.unlink()
                            print(f"   Deleted: {old_cache.name}")
                        except Exception as e:
                            print(f"   Could not delete {old_cache.name}: {e}")

                    print(
                        f"ğŸ’¡ Please run with fresh data to generate new multi-temperature cache"
                    )
                    return None

            except Exception as e:
                print(f"âš ï¸  Could not load cache file: {e}")
                return None

        # No cache available
        print("ğŸ“Š No compatible cache file found")
        return None

    def _generate_features_for_date(
        self, target_date: datetime, weather_data: pd.DataFrame
    ) -> Dict[str, float]:
        """Generate ML features for a specific date using full weather data for multi-temperature prediction"""

        if target_date not in weather_data.index:
            raise ValueError(f"Date {target_date.date()} not found in weather data")

        # Get position in weather data
        date_pos = weather_data.index.get_loc(target_date)

        # Temperature data for all three types
        temp_types = ["max", "min", "mean"]
        temp_data = {}
        for temp_type in temp_types:
            if f"temp_{temp_type}" in weather_data.columns:
                temp_data[temp_type] = weather_data[f"temp_{temp_type}"]
            else:
                # Fallback to old format if new format not available
                if temp_type == "mean" and "temperature" in weather_data.columns:
                    temp_data[temp_type] = weather_data["temperature"]
                else:
                    raise ValueError(f"Temperature data for {temp_type} not found")

        features = {}

        # Temporal features
        day_of_year = target_date.timetuple().tm_yday
        features["day_of_year"] = day_of_year
        features["month"] = target_date.month
        features["sin_doy"] = np.sin(2 * np.pi * day_of_year / 365.25)
        features["cos_doy"] = np.cos(2 * np.pi * day_of_year / 365.25)

        # Lag features for all temperature types
        lag_days = [1, 7, 14, 30]
        for temp_type in temp_types:
            for lag in lag_days:
                try:
                    if date_pos >= lag:
                        features[f"{temp_type}_lag_{lag}"] = temp_data[temp_type].iloc[
                            date_pos - lag
                        ]
                    else:
                        features[f"{temp_type}_lag_{lag}"] = temp_data[temp_type].iloc[
                            max(0, date_pos - 1)
                        ]
                except:
                    # Fallback value
                    features[f"{temp_type}_lag_{lag}"] = temp_data[temp_type].mean()

        # Rolling averages for all temperature types
        for temp_type in temp_types:
            try:
                # 7-day rolling average
                if date_pos >= 8:
                    historical_temps = temp_data[temp_type].iloc[
                        date_pos - 8 : date_pos - 1
                    ]
                    features[f"{temp_type}_roll_7d"] = historical_temps.mean()
                else:
                    features[f"{temp_type}_roll_7d"] = (
                        temp_data[temp_type].iloc[: max(1, date_pos)].mean()
                    )

                # 30-day rolling average
                if date_pos >= 37:
                    historical_temps = temp_data[temp_type].iloc[
                        date_pos - 37 : date_pos - 7
                    ]
                    features[f"{temp_type}_roll_30d"] = historical_temps.mean()
                else:
                    features[f"{temp_type}_roll_30d"] = (
                        temp_data[temp_type].iloc[: max(1, date_pos)].mean()
                    )
            except:
                # Fallback values
                mean_temp = temp_data[temp_type].mean()
                features[f"{temp_type}_roll_7d"] = mean_temp
                features[f"{temp_type}_roll_30d"] = mean_temp

        # Temperature volatility (standard deviation)
        for temp_type in temp_types:
            try:
                if date_pos >= 15:
                    historical_temps = temp_data[temp_type].iloc[
                        date_pos - 15 : date_pos - 1
                    ]
                    features[f"{temp_type}_std_14d"] = historical_temps.std()
                else:
                    features[f"{temp_type}_std_14d"] = (
                        temp_data[temp_type].iloc[: max(1, date_pos)].std()
                    )
            except:
                features[f"{temp_type}_std_14d"] = 5.0  # Reasonable default

        # Temperature range features
        try:
            if date_pos >= 1:
                yesterday_range = (
                    temp_data["max"].iloc[date_pos - 1]
                    - temp_data["min"].iloc[date_pos - 1]
                )
                features["temp_range_lag_1"] = yesterday_range
            else:
                features["temp_range_lag_1"] = (
                    temp_data["max"] - temp_data["min"]
                ).mean()

            if date_pos >= 7:
                week_ago_range = (
                    temp_data["max"].iloc[date_pos - 7]
                    - temp_data["min"].iloc[date_pos - 7]
                )
                features["temp_range_lag_7"] = week_ago_range
            else:
                features["temp_range_lag_7"] = (
                    temp_data["max"] - temp_data["min"]
                ).mean()
        except:
            # Fallback for temperature range
            features["temp_range_lag_1"] = 10.0  # Reasonable default range
            features["temp_range_lag_7"] = 10.0

        # Seasonal features
        features["is_winter"] = 1 if target_date.month in [12, 1, 2] else 0
        features["is_summer"] = 1 if target_date.month in [6, 7, 8] else 0

        return features

    def predict_temperature(
        self,
        forecast_date: Union[str, datetime],
        horizons: List[int] = [1, 3, 7, 14, 30],
    ) -> Dict:
        """
        Generate temperature forecast for a specific date

        Args:
            forecast_date: Date to forecast from (YYYY-MM-DD string or datetime)
            horizons: List of forecast horizons in days

        Returns:
            Dictionary with forecasts and metadata
        """

        if self.model is None:
            raise ValueError("No model trained. Run train_model() first.")

        # Parse forecast date
        if isinstance(forecast_date, str):
            forecast_date = datetime.strptime(forecast_date, "%Y-%m-%d")

        print(f"ğŸ”® Generating forecast from {forecast_date.date()}")

        # Load full weather data for feature generation (not just the sample)
        full_weather_data = self._load_full_weather_data()

        if full_weather_data is None:
            # Fallback to features_data sample if no cache available
            if self.features_data is not None:
                print("ğŸ“Š Using model's training data sample (limited range)")
                full_weather_data = self.features_data
            else:
                raise ValueError(
                    "No weather data available for feature generation. Please run the complete pipeline first."
                )

        # Check if we have data for this date
        if forecast_date not in full_weather_data.index:
            latest_date = full_weather_data.index.max()
            if forecast_date > latest_date:
                print(
                    f"âš ï¸  Using latest available data ({latest_date.date()}) for feature generation"
                )
                forecast_date = latest_date
            else:
                # Find closest available date
                available_dates = full_weather_data.index[
                    full_weather_data.index <= forecast_date
                ]
                if len(available_dates) > 0:
                    forecast_date = available_dates.max()
                    print(f"âš ï¸  Using closest available date: {forecast_date.date()}")
                else:
                    raise ValueError(
                        f"No historical data available for or before {forecast_date.date()}"
                    )

        # Generate features for the forecast date using full data
        features = self._generate_features_for_date(forecast_date, full_weather_data)

        # Get temperature data for seasonal adjustments
        temp_data = {}
        for temp_type in ["max", "min", "mean"]:
            if f"temp_{temp_type}" in full_weather_data.columns:
                temp_data[temp_type] = full_weather_data[f"temp_{temp_type}"]
            elif temp_type == "mean" and "temperature" in full_weather_data.columns:
                temp_data[temp_type] = full_weather_data["temperature"]

        # Create forecasts for different horizons using multi-output prediction
        forecasts = {}

        for horizon in horizons:
            target_date = forecast_date + timedelta(days=horizon)

            if horizon == 1:
                # 1-day forecast: Use current features directly for multi-output prediction
                feature_vector = np.array(
                    [features[name] for name in self.feature_names]
                ).reshape(1, -1)
                feature_vector_scaled = self.scaler.transform(feature_vector)
                predictions = self.model.predict(feature_vector_scaled)[
                    0
                ]  # Returns [max, min, mean]

                temp_max, temp_min, temp_mean = (
                    predictions[0],
                    predictions[1],
                    predictions[2],
                )
                confidence = "high"

            else:
                # Multi-day forecast: Use iterative approach with seasonal adjustments
                # Start with base prediction
                feature_vector = np.array(
                    [features[name] for name in self.feature_names]
                ).reshape(1, -1)
                feature_vector_scaled = self.scaler.transform(feature_vector)
                base_predictions = self.model.predict(feature_vector_scaled)[
                    0
                ]  # [max, min, mean]

                # Apply seasonal adjustments for each temperature type
                adjusted_temps = {}
                target_doy = target_date.timetuple().tm_yday
                current_doy = forecast_date.timetuple().tm_yday

                for i, temp_type in enumerate(["max", "min", "mean"]):
                    base_prediction = base_predictions[i]

                    if temp_type in temp_data:
                        # Get historical temperatures for seasonal adjustment
                        historical_temps_target = temp_data[temp_type][
                            temp_data[temp_type].index.dayofyear == target_doy
                        ]
                        historical_temps_current = temp_data[temp_type][
                            temp_data[temp_type].index.dayofyear == current_doy
                        ]

                        if (
                            len(historical_temps_target) > 0
                            and len(historical_temps_current) > 0
                        ):
                            # Calculate seasonal difference
                            avg_temp_target = historical_temps_target.mean()
                            avg_temp_current = historical_temps_current.mean()
                            seasonal_diff = avg_temp_target - avg_temp_current

                            # Apply seasonal adjustment with decay for longer horizons
                            seasonal_weight = 0.5 * np.exp(
                                -horizon / 14.0
                            )  # Decay over 2 weeks
                            seasonal_adjustment = seasonal_diff * seasonal_weight

                            prediction = base_prediction + seasonal_adjustment
                        else:
                            # Fallback: slight random variation to avoid identical predictions
                            prediction = base_prediction + np.random.normal(0, 0.5)
                    else:
                        prediction = base_prediction + np.random.normal(0, 0.5)

                    # Add some uncertainty for longer horizons
                    if horizon > 7:
                        uncertainty = np.random.normal(0, 0.3 * (horizon / 7.0))
                        prediction += uncertainty

                    adjusted_temps[temp_type] = prediction

                temp_max = adjusted_temps["max"]
                temp_min = adjusted_temps["min"]
                temp_mean = adjusted_temps["mean"]

                # Ensure logical relationships (max >= mean >= min)
                if temp_max < temp_mean:
                    temp_max = temp_mean + abs(temp_max - temp_mean)
                if temp_min > temp_mean:
                    temp_min = temp_mean - abs(temp_min - temp_mean)
                if temp_max < temp_min:
                    temp_max, temp_min = temp_min, temp_max

                # Set confidence based on horizon
                if horizon > 7:
                    confidence = "low"
                elif horizon > 3:
                    confidence = "medium"
                else:
                    confidence = "high"

            forecasts[f"{horizon}_day"] = {
                "date": target_date.strftime("%Y-%m-%d"),
                "temperature_max": round(float(temp_max), 1),
                "temperature_min": round(float(temp_min), 1),
                "temperature_mean": round(float(temp_mean), 1),
                "temperature_range": round(float(temp_max - temp_min), 1),
                "horizon_days": horizon,
                "confidence": confidence,
            }

        # Prepare response
        response = {
            "location": self.location_name,
            "station_id": self.station_id,
            "forecast_from": forecast_date.strftime("%Y-%m-%d"),
            "generated_at": datetime.now().isoformat(),
            "forecasts": forecasts,
            "model_performance": {
                "expected_mae_overall": f"{self.model_performance.get('test_mae_overall', self.model_performance.get('test_mae', 'Unknown')):.3f}Â°C",
                "expected_mae_by_type": (
                    {
                        temp_type: f"{mae:.3f}Â°C"
                        for temp_type, mae in self.model_performance.get(
                            "test_mae_by_type", {}
                        ).items()
                    }
                    if "test_mae_by_type" in self.model_performance
                    else {}
                ),
                "model_type": self.model_performance["model_type"],
                "training_data_end": full_weather_data.index.max().strftime("%Y-%m-%d"),
            },
            "notes": [
                "Forecasts include daily maximum, minimum, and mean temperatures",
                "1-day forecasts use multi-output ML model directly (highest accuracy)",
                "Multi-day forecasts use seasonal adjustments and trend analysis",
                "Temperature relationships are maintained (max â‰¥ mean â‰¥ min)",
                "Confidence decreases with longer forecast horizons",
                f"Based on {len(full_weather_data)} days of historical data",
            ],
        }

        return response

    def save_model(self, filepath: str = None) -> str:
        """
        Save the trained model and pipeline components

        Args:
            filepath: Path to save the model (optional)

        Returns:
            Path where model was saved
        """

        if self.model is None:
            raise ValueError("No model to save. Train a model first.")

        if filepath is None:
            safe_location = self.location_name.replace(" ", "_").replace(",", "")
            filepath = f"weather_model_{safe_location}_{self.station_id}.pkl"

        model_package = {
            "model": self.model,
            "scaler": self.scaler,
            "feature_names": self.feature_names,
            "station_id": self.station_id,
            "location_name": self.location_name,
            "model_performance": self.model_performance,
            "training_date": datetime.now().isoformat(),
            "features_data_sample": self.features_data.tail(
                30
            ),  # Save recent data for feature generation
        }

        with open(filepath, "wb") as f:
            pickle.dump(model_package, f)

        print(f"ğŸ’¾ Model saved to: {filepath}")
        return filepath

    def load_model(self, filepath: str):
        """
        Load a pre-trained model and pipeline components

        Args:
            filepath: Path to the saved model file
        """

        with open(filepath, "rb") as f:
            model_package = pickle.load(f)

        self.model = model_package["model"]
        self.scaler = model_package["scaler"]
        self.feature_names = model_package["feature_names"]
        self.station_id = model_package["station_id"]
        self.location_name = model_package["location_name"]
        self.model_performance = model_package["model_performance"]

        # Restore some sample data for feature generation
        if "features_data_sample" in model_package:
            self.features_data = model_package["features_data_sample"]

        print(f"ğŸ“¥ Model loaded from: {filepath}")
        print(f"ğŸ“ Location: {self.location_name}")

        # Handle different MAE key names for compatibility
        if "test_mae_overall" in self.model_performance:
            # New multi-output format
            mae_overall = self.model_performance["test_mae_overall"]
            print(f"ğŸ¯ Expected performance (overall): {mae_overall:.3f}Â°C")

            if "test_mae_by_type" in self.model_performance:
                print(f"ğŸ¯ Expected performance by type:")
                for temp_type, mae in self.model_performance[
                    "test_mae_by_type"
                ].items():
                    print(f"   {temp_type.capitalize()}: {mae:.3f}Â°C")
        else:
            # Legacy single-output format
            mae_value = self.model_performance.get(
                "test_mae"
            ) or self.model_performance.get("expected_mae", "Unknown")
            mae_display = (
                f"{mae_value:.3f}Â°C"
                if isinstance(mae_value, (int, float))
                else str(mae_value)
            )
            print(f"ğŸ¯ Expected performance: {mae_display}")
            print("   (Legacy single-output model - mean temperature only)")

    def run_complete_pipeline(
        self,
        start_year: int = 1990,
        save_model: bool = True,
        force_download: bool = False,
    ) -> Dict:
        """
        Run the complete pipeline from data download to model training

        Args:
            start_year: Year to start downloading data from
            save_model: Whether to save the trained model
            force_download: Force re-download even if cached data exists

        Returns:
            Dictionary with pipeline results
        """

        print("ğŸš€ Running complete weather forecasting pipeline...")

        # Step 1: Download data (or load from cache)
        raw_data = self.download_historical_data(
            start_year=start_year, force_download=force_download
        )

        # Step 2: Create features
        features_data = self.create_ml_features()

        # Step 3: Train model
        performance = self.train_model()

        # Step 4: Save model (optional)
        model_path = None
        if save_model:
            model_path = self.save_model()

        # Step 5: Generate example forecast
        latest_date = features_data.index.max()
        example_forecast = self.predict_temperature(latest_date)

        results = {
            "pipeline_status": "success",
            "data_downloaded": len(raw_data),
            "features_created": len(features_data),
            "model_performance": performance,
            "model_saved_to": model_path,
            "example_forecast": example_forecast,
        }

        print(f"\nğŸ‰ Pipeline completed successfully!")
        print(f"ğŸ“Š Data: {len(raw_data)} records processed")

        # Display performance based on model type
        if "test_mae_overall" in performance:
            print(f"ğŸ§  Model: {performance['test_mae_overall']:.2f}Â°C MAE (overall)")
            print(f"   Performance by type:")
            for temp_type, mae in performance.get("test_mae_by_type", {}).items():
                print(f"     {temp_type.capitalize()}: {mae:.2f}Â°C MAE")
        else:
            # Legacy format
            test_mae = performance.get(
                "test_mae", performance.get("expected_mae", "Unknown")
            )
            print(
                f"ğŸ§  Model: {test_mae:.2f}Â°C MAE"
                if isinstance(test_mae, (int, float))
                else f"ğŸ§  Model: {test_mae}"
            )

        print(f"ğŸ’¾ Saved: {model_path}")

        return results


def main():
    """Command-line interface for the weather forecasting pipeline"""

    parser = argparse.ArgumentParser(
        description="Unified Weather Forecasting Pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Run complete pipeline for Temagami station (uses cached data if available)
  python weather_forecast.py --station-id 47687 --location "Temagami, ON"
  
  # Force re-download data (ignores cache)
  python weather_forecast.py --station-id 47687 --location "Temagami, ON" --force-download
  
  # Load existing model and make forecasts
  python weather_forecast.py --load-model weather_model_Temagami_ON_47687.pkl --forecast-date 2024-07-15
  
  # Find station IDs at: https://climate.weather.gc.ca/historical_data/search_historic_data_e.html
        """,
    )

    parser.add_argument("--station-id", type=int, help="Environment Canada station ID")
    parser.add_argument(
        "--location", type=str, default="Unknown", help="Human-readable location name"
    )
    parser.add_argument(
        "--start-year",
        type=int,
        default=1990,
        help="Start year for data download (default: 1990)",
    )
    parser.add_argument(
        "--load-model", type=str, help="Path to existing model file to load"
    )
    parser.add_argument(
        "--forecast-date", type=str, help="Date to forecast from (YYYY-MM-DD format)"
    )
    parser.add_argument(
        "--horizons",
        type=str,
        default="1,3,7,14,30",
        help="Forecast horizons in days (comma-separated)",
    )
    parser.add_argument(
        "--no-save", action="store_true", help="Do not save the trained model"
    )
    parser.add_argument(
        "--force-download",
        action="store_true",
        help="Force re-download data even if cached file exists",
    )

    args = parser.parse_args()

    # Parse horizons
    try:
        horizons = [int(h.strip()) for h in args.horizons.split(",")]
    except:
        horizons = [1, 3, 7, 14, 30]

    # Mode 1: Load existing model and make forecasts
    if args.load_model:
        print("Loading existing model...")
        pipeline = WeatherForecastPipeline(0, "Loaded Model")  # Placeholder values
        pipeline.load_model(args.load_model)

        if args.forecast_date:
            forecast = pipeline.predict_temperature(args.forecast_date, horizons)
            print(f"\nğŸ”® Forecast Results:")
            print(f"Location: {forecast['location']}")
            print(f"From: {forecast['forecast_from']}")
            print("\nTemperature Forecasts:")
            for horizon, pred in forecast["forecasts"].items():
                if "temperature_max" in pred:
                    # Multi-temperature format
                    max_temp = pred["temperature_max"]
                    min_temp = pred["temperature_min"]
                    mean_temp = pred["temperature_mean"]
                    temp_range = pred["temperature_range"]
                    confidence = pred["confidence"]
                    confidence_emoji = (
                        "ğŸ¯"
                        if confidence == "high"
                        else "ğŸ“Š" if confidence == "medium" else "ğŸ¤”"
                    )
                    print(
                        f"  {pred['horizon_days']:2d} days ({pred['date']}): {max_temp}Â°C/{min_temp}Â°C (avg: {mean_temp}Â°C, range: {temp_range}Â°C) {confidence_emoji}"
                    )
                else:
                    # Legacy single temperature format
                    temp = pred.get("temperature", "N/A")
                    print(
                        f"  {pred['horizon_days']:2d} days: {temp}Â°C on {pred['date']}"
                    )
        else:
            print("Use --forecast-date to generate forecasts")

    # Mode 2: Run complete pipeline
    elif args.station_id:
        pipeline = WeatherForecastPipeline(args.station_id, args.location)
        results = pipeline.run_complete_pipeline(
            start_year=args.start_year,
            save_model=not args.no_save,
            force_download=args.force_download,
        )

        print(f"\nğŸ“‹ Example Forecast:")
        example = results["example_forecast"]
        print(f"Location: {example['location']}")
        print(f"Forecast from: {example['forecast_from']}")
        print(f"Temperature predictions:")
        for horizon, pred in example["forecasts"].items():
            if "temperature_max" in pred:
                # New multi-output format
                max_temp = pred["temperature_max"]
                min_temp = pred["temperature_min"]
                mean_temp = pred["temperature_mean"]
                temp_range = pred["temperature_range"]
                confidence = pred["confidence"]
                confidence_emoji = (
                    "ğŸ¯"
                    if confidence == "high"
                    else "ğŸ“Š" if confidence == "medium" else "ğŸ¤”"
                )
                print(
                    f"  {pred['horizon_days']:2d} days ({pred['date']}): {max_temp}Â°C/{min_temp}Â°C (avg: {mean_temp}Â°C, range: {temp_range}Â°C) {confidence_emoji}"
                )
            else:
                # Legacy single-output format
                temp = pred.get("temperature", "N/A")
                print(f"  {pred['horizon_days']:2d} days: {temp}Â°C on {pred['date']}")

    else:
        parser.print_help()
        print(f"\nQuick start:")
        print(
            f'  python weather_forecast.py --station-id 47687 --location "Temagami, ON"'
        )
        print(
            f'  python weather_forecast.py --station-id 47687 --location "Temagami, ON" --force-download  # Re-download data'
        )


if __name__ == "__main__":
    main()
