{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from datetime import datetime, timedelta\n",
    "import itertools\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 387\u001b[39m\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forecaster, validation_results, horizon_metrics\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m     forecaster, results, metrics = \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 358\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    356\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Main SARIMA modeling pipeline\"\"\"\u001b[39;00m\n\u001b[32m    357\u001b[39m \u001b[38;5;66;03m# Initialize forecaster\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m forecaster = \u001b[43mSARIMAForecaster\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemagami_features.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[38;5;66;03m# Check stationarity\u001b[39;00m\n\u001b[32m    361\u001b[39m forecaster.check_stationarity(forecaster.temp_series)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mSARIMAForecaster.__init__\u001b[39m\u001b[34m(self, data_path)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_path=\u001b[33m\"\u001b[39m\u001b[33mtemagami_features.csv\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      5\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load the feature-engineered data\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28mself\u001b[39m.df = \u001b[43mpd\u001b[49m.read_csv(data_path, index_col=\u001b[32m0\u001b[39m, parse_dates=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mself\u001b[39m.temp_series = \u001b[38;5;28mself\u001b[39m.df[\u001b[33m'\u001b[39m\u001b[33mt_mean\u001b[39m\u001b[33m'\u001b[39m].copy()\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded temperature series: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.temp_series)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m observations\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "class SARIMAForecaster:\n",
    "    \"\"\"SARIMA model for temperature forecasting with walk-forward validation\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path=\"temagami_features.csv\"):\n",
    "        \"\"\"Load the feature-engineered data\"\"\"\n",
    "        self.df = pd.read_csv(data_path, index_col=0, parse_dates=True)\n",
    "        self.temp_series = self.df['t_mean'].copy()\n",
    "        print(f\"Loaded temperature series: {len(self.temp_series)} observations\")\n",
    "        print(f\"Date range: {self.temp_series.index.min().date()} to {self.temp_series.index.max().date()}\")\n",
    "        \n",
    "    def check_stationarity(self, series, title=\"Temperature Series\"):\n",
    "        \"\"\"Check if series is stationary using Augmented Dickey-Fuller test\"\"\"\n",
    "        print(f\"\\nStationarity Test for {title}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Augmented Dickey-Fuller test\n",
    "        adf_result = adfuller(series.dropna())\n",
    "        \n",
    "        print(f\"ADF Statistic: {adf_result[0]:.6f}\")\n",
    "        print(f\"p-value: {adf_result[1]:.6f}\")\n",
    "        print(f\"Critical Values:\")\n",
    "        for key, value in adf_result[4].items():\n",
    "            print(f\"\\t{key}: {value:.3f}\")\n",
    "        \n",
    "        if adf_result[1] <= 0.05:\n",
    "            print(\"✓ Series is stationary (reject null hypothesis)\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"✗ Series is non-stationary (fail to reject null hypothesis)\")\n",
    "            return False\n",
    "    \n",
    "    def difference_series(self, series, seasonal_periods=365):\n",
    "        \"\"\"Apply regular and seasonal differencing\"\"\"\n",
    "        print(f\"\\nApplying differencing...\")\n",
    "        \n",
    "        # First difference\n",
    "        diff1 = series.diff().dropna()\n",
    "        is_stationary = self.check_stationarity(diff1, \"First Differenced\")\n",
    "        \n",
    "        if is_stationary:\n",
    "            print(\"First differencing achieved stationarity\")\n",
    "            return diff1, (1, 0)\n",
    "        \n",
    "        # Seasonal difference\n",
    "        seasonal_diff = series.diff(seasonal_periods).dropna()\n",
    "        is_seasonal_stationary = self.check_stationarity(seasonal_diff, \"Seasonal Differenced\")\n",
    "        \n",
    "        if is_seasonal_stationary:\n",
    "            print(\"Seasonal differencing achieved stationarity\")\n",
    "            return seasonal_diff, (0, 1)\n",
    "        \n",
    "        # Both regular and seasonal differencing\n",
    "        both_diff = series.diff().diff(seasonal_periods).dropna()\n",
    "        is_both_stationary = self.check_stationarity(both_diff, \"Both Differenced\")\n",
    "        \n",
    "        if is_both_stationary:\n",
    "            print(\"Both regular and seasonal differencing achieved stationarity\")\n",
    "            return both_diff, (1, 1)\n",
    "        \n",
    "        print(\"Warning: Could not achieve stationarity with standard differencing\")\n",
    "        return diff1, (1, 0)\n",
    "    \n",
    "    def plot_diagnostics(self, series, title=\"Temperature Series\"):\n",
    "        \"\"\"Plot ACF and PACF for model identification\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Time series plot\n",
    "        series.plot(ax=axes[0,0], title=f'{title} - Time Series')\n",
    "        axes[0,0].set_ylabel('Temperature (°C)')\n",
    "        \n",
    "        # ACF plot\n",
    "        plot_acf(series.dropna(), ax=axes[0,1], lags=50, title=f'{title} - ACF')\n",
    "        \n",
    "        # PACF plot\n",
    "        plot_pacf(series.dropna(), ax=axes[1,0], lags=50, title=f'{title} - PACF')\n",
    "        \n",
    "        # Distribution\n",
    "        series.hist(bins=50, ax=axes[1,1], alpha=0.7)\n",
    "        axes[1,1].set_title(f'{title} - Distribution')\n",
    "        axes[1,1].set_xlabel('Temperature (°C)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def grid_search_sarima(self, train_data, max_order=2, seasonal_periods=365):\n",
    "        \"\"\"Grid search for best SARIMA parameters\"\"\"\n",
    "        print(f\"\\nGrid searching SARIMA parameters...\")\n",
    "        print(\"This may take several minutes...\")\n",
    "        \n",
    "        # Define parameter ranges\n",
    "        p_values = range(0, max_order + 1)\n",
    "        d_values = [0, 1]  # Based on stationarity tests\n",
    "        q_values = range(0, max_order + 1)\n",
    "        \n",
    "        # Seasonal parameters (keep small for computational efficiency)\n",
    "        P_values = [0, 1]\n",
    "        D_values = [0, 1] \n",
    "        Q_values = [0, 1]\n",
    "        \n",
    "        best_aic = np.inf\n",
    "        best_params = None\n",
    "        best_seasonal_params = None\n",
    "        results = []\n",
    "        \n",
    "        total_combinations = len(p_values) * len(d_values) * len(q_values) * len(P_values) * len(D_values) * len(Q_values)\n",
    "        current_combination = 0\n",
    "        \n",
    "        for p, d, q in itertools.product(p_values, d_values, q_values):\n",
    "            for P, D, Q in itertools.product(P_values, D_values, Q_values):\n",
    "                current_combination += 1\n",
    "                \n",
    "                if current_combination % 10 == 0:\n",
    "                    print(f\"Progress: {current_combination}/{total_combinations} combinations tested\")\n",
    "                \n",
    "                try:\n",
    "                    # Fit SARIMA model\n",
    "                    model = SARIMAX(train_data, \n",
    "                                   order=(p, d, q),\n",
    "                                   seasonal_order=(P, D, Q, seasonal_periods),\n",
    "                                   enforce_stationarity=False,\n",
    "                                   enforce_invertibility=False)\n",
    "                    \n",
    "                    fitted_model = model.fit(disp=False, maxiter=100)\n",
    "                    \n",
    "                    # Store results\n",
    "                    results.append({\n",
    "                        'order': (p, d, q),\n",
    "                        'seasonal_order': (P, D, Q, seasonal_periods),\n",
    "                        'aic': fitted_model.aic,\n",
    "                        'bic': fitted_model.bic,\n",
    "                        'converged': fitted_model.mle_retvals['converged']\n",
    "                    })\n",
    "                    \n",
    "                    # Update best model\n",
    "                    if fitted_model.aic < best_aic and fitted_model.mle_retvals['converged']:\n",
    "                        best_aic = fitted_model.aic\n",
    "                        best_params = (p, d, q)\n",
    "                        best_seasonal_params = (P, D, Q, seasonal_periods)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    # Skip problematic parameter combinations\n",
    "                    continue\n",
    "        \n",
    "        print(f\"\\nGrid search completed!\")\n",
    "        print(f\"Best parameters: SARIMA{best_params} x {best_seasonal_params}\")\n",
    "        print(f\"Best AIC: {best_aic:.2f}\")\n",
    "        \n",
    "        # Show top 5 models\n",
    "        results_df = pd.DataFrame(results)\n",
    "        if len(results_df) > 0:\n",
    "            results_df = results_df[results_df['converged'] == True]\n",
    "            top_models = results_df.nsmallest(5, 'aic')\n",
    "            print(f\"\\nTop 5 models by AIC:\")\n",
    "            for idx, row in top_models.iterrows():\n",
    "                print(f\"SARIMA{row['order']} x {row['seasonal_order']}: AIC={row['aic']:.2f}\")\n",
    "        \n",
    "        self.best_params = best_params\n",
    "        self.best_seasonal_params = best_seasonal_params\n",
    "        self.grid_search_results = results_df if len(results_df) > 0 else None\n",
    "        \n",
    "        return best_params, best_seasonal_params\n",
    "    \n",
    "    def fit_sarima(self, train_data, order=None, seasonal_order=None):\n",
    "        \"\"\"Fit SARIMA model with given or best parameters\"\"\"\n",
    "        if order is None:\n",
    "            order = getattr(self, 'best_params', (1, 1, 1))\n",
    "        if seasonal_order is None:\n",
    "            seasonal_order = getattr(self, 'best_seasonal_params', (1, 1, 1, 365))\n",
    "        \n",
    "        print(f\"\\nFitting SARIMA{order} x {seasonal_order}\")\n",
    "        \n",
    "        try:\n",
    "            model = SARIMAX(train_data,\n",
    "                           order=order,\n",
    "                           seasonal_order=seasonal_order,\n",
    "                           enforce_stationarity=False,\n",
    "                           enforce_invertibility=False)\n",
    "            \n",
    "            fitted_model = model.fit(disp=False, maxiter=200)\n",
    "            \n",
    "            print(f\"Model fitted successfully!\")\n",
    "            print(f\"AIC: {fitted_model.aic:.2f}\")\n",
    "            print(f\"BIC: {fitted_model.bic:.2f}\")\n",
    "            print(f\"Log-likelihood: {fitted_model.llf:.2f}\")\n",
    "            \n",
    "            self.fitted_model = fitted_model\n",
    "            return fitted_model\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fitting SARIMA model: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def walk_forward_validation(self, test_years=3, forecast_horizon=30):\n",
    "        \"\"\"Walk-forward validation for SARIMA model\"\"\"\n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(\"SARIMA WALK-FORWARD VALIDATION\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Split data\n",
    "        test_start_year = self.temp_series.index.max().year - test_years + 1\n",
    "        train_data = self.temp_series[self.temp_series.index.year < test_start_year]\n",
    "        test_data = self.temp_series[self.temp_series.index.year >= test_start_year]\n",
    "        \n",
    "        print(f\"Training: {train_data.index.min().date()} to {train_data.index.max().date()}\")\n",
    "        print(f\"Testing: {test_data.index.min().date()} to {test_data.index.max().date()}\")\n",
    "        \n",
    "        # Find best parameters on training data\n",
    "        if not hasattr(self, 'best_params'):\n",
    "            print(\"Finding optimal parameters...\")\n",
    "            self.grid_search_sarima(train_data, max_order=2)\n",
    "        \n",
    "        # Walk-forward validation\n",
    "        results = []\n",
    "        forecast_dates = []\n",
    "        \n",
    "        # Start with initial training window\n",
    "        current_train = train_data.copy()\n",
    "        \n",
    "        for test_date in test_data.index[::7]:  # Test every 7 days to speed up\n",
    "            print(f\"Forecasting from {test_date.date()}...\")\n",
    "            \n",
    "            try:\n",
    "                # Fit model on current training data\n",
    "                model = SARIMAX(current_train,\n",
    "                               order=self.best_params,\n",
    "                               seasonal_order=self.best_seasonal_params,\n",
    "                               enforce_stationarity=False,\n",
    "                               enforce_invertibility=False)\n",
    "                \n",
    "                fitted_model = model.fit(disp=False, maxiter=100)\n",
    "                \n",
    "                # Generate forecasts\n",
    "                forecasts = fitted_model.forecast(steps=forecast_horizon)\n",
    "                forecast_index = pd.date_range(start=current_train.index[-1] + timedelta(days=1),\n",
    "                                             periods=forecast_horizon, freq='D')\n",
    "                \n",
    "                # Collect actual vs predicted for available dates\n",
    "                for i, forecast_date in enumerate(forecast_index):\n",
    "                    if forecast_date in test_data.index:\n",
    "                        actual = test_data.loc[forecast_date]\n",
    "                        predicted = forecasts.iloc[i] if isinstance(forecasts, pd.Series) else forecasts[i]\n",
    "                        \n",
    "                        results.append({\n",
    "                            'forecast_origin': test_date,\n",
    "                            'forecast_date': forecast_date,\n",
    "                            'horizon': i + 1,\n",
    "                            'actual': actual,\n",
    "                            'predicted': predicted,\n",
    "                            'error': abs(actual - predicted)\n",
    "                        })\n",
    "                \n",
    "                # Update training data (expanding window)\n",
    "                if test_date in test_data.index:\n",
    "                    current_train = pd.concat([current_train, test_data.loc[test_date:test_date]])\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error forecasting from {test_date.date()}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        self.validation_results = pd.DataFrame(results)\n",
    "        return self.validation_results\n",
    "    \n",
    "    def evaluate_sarima_performance(self):\n",
    "        \"\"\"Evaluate SARIMA performance by horizon\"\"\"\n",
    "        if not hasattr(self, 'validation_results'):\n",
    "            print(\"Run walk_forward_validation first\")\n",
    "            return None\n",
    "        \n",
    "        # Calculate metrics by horizon\n",
    "        horizon_metrics = self.validation_results.groupby('horizon').agg({\n",
    "            'error': ['mean', 'std', 'count'],\n",
    "            'actual': 'mean',\n",
    "            'predicted': 'mean'\n",
    "        }).round(3)\n",
    "        \n",
    "        horizon_metrics.columns = ['MAE', 'STD_Error', 'N_Forecasts', 'Mean_Actual', 'Mean_Predicted']\n",
    "        \n",
    "        print(f\"\\nSARIMA Performance by Horizon:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"{'Horizon':<8} {'MAE':<8} {'N_Forecasts':<12} {'Actual':<8} {'Predicted':<10}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for horizon in sorted(horizon_metrics.index):\n",
    "            if horizon <= 30:  # Show up to 30 days\n",
    "                row = horizon_metrics.loc[horizon]\n",
    "                print(f\"{horizon:<8} {row['MAE']:<8.2f} {int(row['N_Forecasts']):<12} {row['Mean_Actual']:<8.1f} {row['Mean_Predicted']:<10.1f}\")\n",
    "        \n",
    "        return horizon_metrics\n",
    "    \n",
    "    def compare_with_baselines(self, baseline_results_path=\"baseline_results.csv\"):\n",
    "        \"\"\"Compare SARIMA with baseline models\"\"\"\n",
    "        if not hasattr(self, 'validation_results'):\n",
    "            print(\"Run walk_forward_validation first\")\n",
    "            return\n",
    "        \n",
    "        # Load baseline results\n",
    "        baseline_df = pd.read_csv(baseline_results_path)\n",
    "        \n",
    "        # Get SARIMA results by horizon\n",
    "        sarima_metrics = self.validation_results.groupby('horizon')['error'].mean()\n",
    "        \n",
    "        # Create comparison\n",
    "        comparison = []\n",
    "        for horizon in range(1, 31):\n",
    "            baseline_row = baseline_df[baseline_df['Horizon'] == horizon]\n",
    "            if len(baseline_row) > 0 and horizon in sarima_metrics.index:\n",
    "                comparison.append({\n",
    "                    'Horizon': horizon,\n",
    "                    'SARIMA_MAE': sarima_metrics[horizon],\n",
    "                    'Climatology_MAE': baseline_row['Climatology_MAE'].iloc[0],\n",
    "                    'Seasonal_Naive_MAE': baseline_row['Seasonal_Naive_MAE'].iloc[0],\n",
    "                    'Persistence_MAE': baseline_row['Persistence_MAE'].iloc[0]\n",
    "                })\n",
    "        \n",
    "        comparison_df = pd.DataFrame(comparison)\n",
    "        \n",
    "        # Plot comparison\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        ax.plot(comparison_df['Horizon'], comparison_df['SARIMA_MAE'], 'o-', \n",
    "               label='SARIMA', linewidth=2, markersize=4, color='red')\n",
    "        ax.plot(comparison_df['Horizon'], comparison_df['Climatology_MAE'], 's-', \n",
    "               label='Climatology', linewidth=2, markersize=4, color='blue')\n",
    "        ax.plot(comparison_df['Horizon'], comparison_df['Seasonal_Naive_MAE'], '^-', \n",
    "               label='Seasonal Naïve', linewidth=2, markersize=4, color='green')\n",
    "        ax.plot(comparison_df['Horizon'], comparison_df['Persistence_MAE'], 'd-', \n",
    "               label='Persistence', linewidth=2, markersize=4, color='orange')\n",
    "        \n",
    "        ax.set_xlabel('Forecast Horizon (days)')\n",
    "        ax.set_ylabel('Mean Absolute Error (°C)')\n",
    "        ax.set_title('SARIMA vs Baseline Models')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('sarima_vs_baselines.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nSARIMA vs Baselines Summary:\")\n",
    "        print(\"-\" * 40)\n",
    "        horizons = [1, 7, 14, 30]\n",
    "        for h in horizons:\n",
    "            row = comparison_df[comparison_df['Horizon'] == h]\n",
    "            if len(row) > 0:\n",
    "                row = row.iloc[0]\n",
    "                best_baseline = min(row['Climatology_MAE'], row['Seasonal_Naive_MAE'], row['Persistence_MAE'])\n",
    "                improvement = ((best_baseline - row['SARIMA_MAE']) / best_baseline) * 100\n",
    "                print(f\"{h:2d} days: SARIMA {row['SARIMA_MAE']:.2f}°C vs Best Baseline {best_baseline:.2f}°C \"\n",
    "                      f\"({'↑' if improvement > 0 else '↓'}{improvement:+.1f}%)\")\n",
    "        \n",
    "        self.comparison_df = comparison_df\n",
    "        return comparison_df\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main SARIMA modeling pipeline\"\"\"\n",
    "    # Initialize forecaster\n",
    "    forecaster = SARIMAForecaster(\"temagami_features.csv\")\n",
    "    \n",
    "    # Check stationarity\n",
    "    forecaster.check_stationarity(forecaster.temp_series)\n",
    "    \n",
    "    # Apply differencing if needed\n",
    "    diff_series, diff_orders = forecaster.difference_series(forecaster.temp_series)\n",
    "    \n",
    "    # Plot diagnostics\n",
    "    forecaster.plot_diagnostics(forecaster.temp_series, \"Original Temperature\")\n",
    "    forecaster.plot_diagnostics(diff_series, \"Differenced Temperature\")\n",
    "    \n",
    "    # Grid search for best parameters (this will take a while)\n",
    "    print(\"\\nStarting grid search (this may take 10-15 minutes)...\")\n",
    "    best_params, best_seasonal_params = forecaster.grid_search_sarima(\n",
    "        forecaster.temp_series[:-365], max_order=2)  # Hold out last year for validation\n",
    "    \n",
    "    # Walk-forward validation\n",
    "    validation_results = forecaster.walk_forward_validation(test_years=3, forecast_horizon=30)\n",
    "    \n",
    "    # Evaluate performance\n",
    "    horizon_metrics = forecaster.evaluate_sarima_performance()\n",
    "    \n",
    "    # Compare with baselines\n",
    "    comparison = forecaster.compare_with_baselines()\n",
    "    \n",
    "    return forecaster, validation_results, horizon_metrics\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    forecaster, results, metrics = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
